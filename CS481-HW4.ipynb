{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_4(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZIe3ArSmZXe"
      },
      "source": [
        "# Please find the comment: \"# your code here\" and fill in your code. \n",
        "- Please keep the comment and do not delete it.\n",
        "- The expected output has shown below each cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTuBnffvmcPD"
      },
      "source": [
        "# Build a n-gram language model using the brown corpus\n",
        "- In this task, you are going to build a n-gram language model using the brown corpus; \n",
        "- You will build a unigram model, a bigram model, and a trigram model.\n",
        "- You will then need to calculate the probability for a given sentence based on the your language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c6aGJwZWTmK"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown \n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlM7q7HjWTmL",
        "outputId": "e358a22d-0358-4e2e-f6fd-f1e17341362f"
      },
      "source": [
        "nltk.download('brown')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGvjDk7eWTmM"
      },
      "source": [
        "# the sentence you are going to calculate the probability for\n",
        "test_sent = \"Congratulations you have made it\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rorb2DjpWTmN",
        "outputId": "e0482037-3970-4d52-8955-be516ab71757"
      },
      "source": [
        "# each sentence is stored as a list of tokens\n",
        "brown.sents()[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of',\n",
              " \"Atlanta's\",\n",
              " 'recent',\n",
              " 'primary',\n",
              " 'election',\n",
              " 'produced',\n",
              " '``',\n",
              " 'no',\n",
              " 'evidence',\n",
              " \"''\",\n",
              " 'that',\n",
              " 'any',\n",
              " 'irregularities',\n",
              " 'took',\n",
              " 'place',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7htp2GsanYJd"
      },
      "source": [
        "- Build the unigram model: P(w1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZzVEX7pWTmO"
      },
      "source": [
        "# Count frequency of unigrams\n",
        "unigram_model = defaultdict(lambda: 0)\n",
        "for sentence in brown.sents():\n",
        "    for w1 in sentence:\n",
        "        unigram_model[w1] += 1\n",
        "        \n",
        "# change counts to probability: P(w1) = count(w1)/total counts of all unigrams\n",
        "for w1 in unigram_model:\n",
        "    total_count = sum(unigram_model.values())# your code here \n",
        "    unigram_model[w1] = unigram_model[w1]/total_count # your code here "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evqyAcY4ld_1",
        "outputId": "ddf0f1eb-654c-44ab-9c76-2687261a9c46"
      },
      "source": [
        "# check the unigram model\n",
        "print(unigram_model['Chicago'])\n",
        "print(unigram_model['you']) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0003902803894980554\n",
            "0.00566839451208122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt2OiR5BWTmP",
        "outputId": "9413f9b5-ee0f-48f9-90d8-b8c0a22760ae"
      },
      "source": [
        "# calculate the sentence probability using the unigram model\n",
        "# P('Congratulations you have made it') = P('Congratulations')*P(you)*P(have)*P(made)*P(it)\n",
        "P_sent = 1\n",
        "for wd in test_sent.split():\n",
        "    print(\"P(%s): %.5f\" % (wd, unigram_model[wd]))\n",
        "    P_sent = P_sent*unigram_model[wd]\n",
        "\n",
        "print(\"P(%s) based on unigram model is:\" % (test_sent),P_sent)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(Congratulations): 0.00002\n",
            "P(you): 0.00567\n",
            "P(have): 0.00519\n",
            "P(made): 0.00202\n",
            "P(it): 0.00872\n",
            "P(Congratulations you have made it) based on unigram model is: 1.0170928774991854e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKivrZJwn3DI"
      },
      "source": [
        "- Build the bigram model: P(w2|w1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gk34gG-WTmR"
      },
      "source": [
        "# Create a dict of dict to store bigram frequency: dict[key] = {key_1:value_1; key_2:value_2;...}\n",
        "bigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of bigrams\n",
        "for sentence in brown.sents():\n",
        "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n",
        "        bigram_model[w1][w2] += 1\n",
        "        \n",
        "# Transform the counts to probabilities: P(w2|w1) = count(w1_w2)/total counts of all bigrams that start with w1: (w1, wi)\n",
        "for w1 in bigram_model:\n",
        "    total_count = float(sum(bigram_model[w1].values()))\n",
        "    for w2 in bigram_model[w1]:\n",
        "        bigram_model[w1][w2] /= total_count"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFRsQuIHWTmR",
        "outputId": "97149def-4138-450c-f0be-506eb5678fe4"
      },
      "source": [
        "# check the bigram model: P('job'|'good')\n",
        "bigram_model['good']['(']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001303780964797914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5-kEdczlTLT",
        "outputId": "af60c5ff-d252-4813-e43d-7bca709706dc"
      },
      "source": [
        "# check all the possible w2 in the bigram ('good', w2)\n",
        "dict(bigram_model['good'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"''\": 0.010430247718383311,\n",
              " '(': 0.001303780964797914,\n",
              " ',': 0.0469361147327249,\n",
              " '--': 0.001303780964797914,\n",
              " '.': 0.05997392438070404,\n",
              " ':': 0.002607561929595828,\n",
              " ';': 0.003911342894393742,\n",
              " '?': 0.002607561929595828,\n",
              " 'American': 0.001303780964797914,\n",
              " 'Baptist': 0.001303780964797914,\n",
              " 'British': 0.001303780964797914,\n",
              " 'Catholic': 0.001303780964797914,\n",
              " 'Catholics': 0.001303780964797914,\n",
              " 'Democrat': 0.001303780964797914,\n",
              " 'English': 0.002607561929595828,\n",
              " 'Japanese': 0.001303780964797914,\n",
              " 'Jew': 0.001303780964797914,\n",
              " 'Lord': 0.001303780964797914,\n",
              " 'Mayor': 0.001303780964797914,\n",
              " None: 0.001303780964797914,\n",
              " 'Protestant': 0.001303780964797914,\n",
              " 'Virgin': 0.001303780964797914,\n",
              " '``': 0.001303780964797914,\n",
              " 'a': 0.003911342894393742,\n",
              " 'abaringe': 0.001303780964797914,\n",
              " 'address': 0.001303780964797914,\n",
              " 'advantage': 0.001303780964797914,\n",
              " 'agreement': 0.001303780964797914,\n",
              " 'although': 0.001303780964797914,\n",
              " 'am': 0.001303780964797914,\n",
              " 'an': 0.001303780964797914,\n",
              " 'and': 0.02998696219035202,\n",
              " 'animal': 0.001303780964797914,\n",
              " 'antique': 0.001303780964797914,\n",
              " 'antiseptic': 0.001303780964797914,\n",
              " 'appetite': 0.001303780964797914,\n",
              " 'approximation': 0.002607561929595828,\n",
              " 'architect': 0.001303780964797914,\n",
              " 'are': 0.001303780964797914,\n",
              " 'as': 0.020860495436766623,\n",
              " 'at': 0.007822685788787484,\n",
              " 'authority': 0.001303780964797914,\n",
              " 'balance': 0.001303780964797914,\n",
              " 'ball': 0.001303780964797914,\n",
              " 'ballplayer': 0.001303780964797914,\n",
              " 'because': 0.001303780964797914,\n",
              " 'behavior': 0.002607561929595828,\n",
              " 'bets': 0.001303780964797914,\n",
              " 'bill': 0.001303780964797914,\n",
              " 'bills': 0.001303780964797914,\n",
              " 'binge': 0.001303780964797914,\n",
              " 'biology': 0.001303780964797914,\n",
              " 'bit': 0.001303780964797914,\n",
              " 'bite': 0.001303780964797914,\n",
              " 'biz': 0.001303780964797914,\n",
              " 'blend': 0.001303780964797914,\n",
              " 'body': 0.002607561929595828,\n",
              " 'books': 0.001303780964797914,\n",
              " 'boy': 0.002607561929595828,\n",
              " 'boys': 0.001303780964797914,\n",
              " 'breakfast': 0.001303780964797914,\n",
              " 'brood': 0.001303780964797914,\n",
              " 'bunters': 0.001303780964797914,\n",
              " 'can': 0.001303780964797914,\n",
              " 'care': 0.001303780964797914,\n",
              " 'cause': 0.002607561929595828,\n",
              " 'chance': 0.001303780964797914,\n",
              " 'character': 0.001303780964797914,\n",
              " 'cheer': 0.001303780964797914,\n",
              " 'choice': 0.001303780964797914,\n",
              " 'chouise': 0.001303780964797914,\n",
              " 'church': 0.001303780964797914,\n",
              " 'churchgoing': 0.001303780964797914,\n",
              " 'city': 0.001303780964797914,\n",
              " 'classical': 0.001303780964797914,\n",
              " 'clothes': 0.001303780964797914,\n",
              " 'cognac': 0.001303780964797914,\n",
              " 'college': 0.002607561929595828,\n",
              " 'colts': 0.001303780964797914,\n",
              " 'comedian': 0.001303780964797914,\n",
              " 'comedy': 0.001303780964797914,\n",
              " 'company': 0.002607561929595828,\n",
              " 'condition': 0.005215123859191656,\n",
              " 'connections': 0.001303780964797914,\n",
              " 'conscience': 0.002607561929595828,\n",
              " 'conservation': 0.001303780964797914,\n",
              " 'cook': 0.001303780964797914,\n",
              " 'corporation': 0.001303780964797914,\n",
              " 'could': 0.002607561929595828,\n",
              " 'coverage': 0.001303780964797914,\n",
              " 'cow': 0.001303780964797914,\n",
              " 'crops': 0.001303780964797914,\n",
              " 'crumbly': 0.001303780964797914,\n",
              " 'customer': 0.003911342894393742,\n",
              " 'day': 0.003911342894393742,\n",
              " 'days': 0.001303780964797914,\n",
              " 'deal': 0.035202086049543675,\n",
              " 'debauchery': 0.001303780964797914,\n",
              " 'decision': 0.001303780964797914,\n",
              " 'decorator': 0.001303780964797914,\n",
              " 'definition': 0.001303780964797914,\n",
              " 'detective': 0.001303780964797914,\n",
              " 'diet': 0.001303780964797914,\n",
              " 'dinner': 0.001303780964797914,\n",
              " 'directly': 0.001303780964797914,\n",
              " 'disposition': 0.001303780964797914,\n",
              " 'dollar': 0.001303780964797914,\n",
              " 'drama': 0.001303780964797914,\n",
              " 'economy': 0.001303780964797914,\n",
              " 'effect': 0.002607561929595828,\n",
              " 'eight': 0.001303780964797914,\n",
              " 'enough': 0.007822685788787484,\n",
              " 'estimates': 0.001303780964797914,\n",
              " 'example': 0.003911342894393742,\n",
              " 'examples': 0.002607561929595828,\n",
              " 'excuse': 0.001303780964797914,\n",
              " 'faith': 0.002607561929595828,\n",
              " 'family': 0.002607561929595828,\n",
              " 'fat': 0.001303780964797914,\n",
              " 'father': 0.001303780964797914,\n",
              " \"father's\": 0.001303780964797914,\n",
              " 'feeling': 0.005215123859191656,\n",
              " 'fellowship': 0.002607561929595828,\n",
              " 'fiction': 0.001303780964797914,\n",
              " 'fight': 0.001303780964797914,\n",
              " 'fighter': 0.001303780964797914,\n",
              " 'first': 0.001303780964797914,\n",
              " 'flowing': 0.001303780964797914,\n",
              " 'flushing': 0.001303780964797914,\n",
              " 'food': 0.002607561929595828,\n",
              " 'for': 0.03259452411994785,\n",
              " 'form': 0.001303780964797914,\n",
              " 'formulation': 0.001303780964797914,\n",
              " 'fortune': 0.003911342894393742,\n",
              " 'friend': 0.00651890482398957,\n",
              " 'friends': 0.005215123859191656,\n",
              " 'from': 0.002607561929595828,\n",
              " 'frost': 0.001303780964797914,\n",
              " 'full': 0.001303780964797914,\n",
              " 'gait': 0.001303780964797914,\n",
              " 'garden': 0.001303780964797914,\n",
              " 'girl': 0.002607561929595828,\n",
              " 'government': 0.001303780964797914,\n",
              " 'graces': 0.001303780964797914,\n",
              " 'grade': 0.002607561929595828,\n",
              " 'grass': 0.001303780964797914,\n",
              " 'guys': 0.002607561929595828,\n",
              " 'hard': 0.001303780964797914,\n",
              " 'hardy': 0.001303780964797914,\n",
              " 'health': 0.010430247718383311,\n",
              " 'his': 0.001303780964797914,\n",
              " 'homes': 0.001303780964797914,\n",
              " 'humor': 0.003911342894393742,\n",
              " 'idea': 0.007822685788787484,\n",
              " 'impresser': 0.001303780964797914,\n",
              " 'impression': 0.002607561929595828,\n",
              " 'in': 0.005215123859191656,\n",
              " 'increase': 0.001303780964797914,\n",
              " 'indication': 0.001303780964797914,\n",
              " 'individual': 0.001303780964797914,\n",
              " 'infield': 0.001303780964797914,\n",
              " 'initial': 0.001303780964797914,\n",
              " 'intelligence': 0.001303780964797914,\n",
              " 'intentions': 0.005215123859191656,\n",
              " 'investment': 0.001303780964797914,\n",
              " 'is': 0.002607561929595828,\n",
              " 'job': 0.010430247718383311,\n",
              " 'judge': 0.001303780964797914,\n",
              " 'judgment': 0.001303780964797914,\n",
              " 'kind': 0.001303780964797914,\n",
              " 'knight': 0.001303780964797914,\n",
              " 'lake': 0.001303780964797914,\n",
              " 'land': 0.001303780964797914,\n",
              " 'landscaping': 0.001303780964797914,\n",
              " 'legislation': 0.002607561929595828,\n",
              " 'lesson': 0.001303780964797914,\n",
              " 'letter': 0.001303780964797914,\n",
              " 'levels': 0.001303780964797914,\n",
              " 'liaison': 0.001303780964797914,\n",
              " 'life': 0.001303780964797914,\n",
              " 'linguist-anthropologist': 0.001303780964797914,\n",
              " 'literature': 0.001303780964797914,\n",
              " 'little': 0.001303780964797914,\n",
              " 'long': 0.001303780964797914,\n",
              " 'look': 0.00651890482398957,\n",
              " 'looking': 0.002607561929595828,\n",
              " 'looks': 0.003911342894393742,\n",
              " 'luck': 0.009126466753585397,\n",
              " 'lucks': 0.001303780964797914,\n",
              " 'magazines': 0.001303780964797914,\n",
              " 'man': 0.010430247718383311,\n",
              " 'manager': 0.001303780964797914,\n",
              " 'many': 0.011734028683181226,\n",
              " 'map': 0.001303780964797914,\n",
              " 'mark': 0.001303780964797914,\n",
              " 'marketing': 0.001303780964797914,\n",
              " 'marks': 0.001303780964797914,\n",
              " 'marriage': 0.001303780964797914,\n",
              " 'meal': 0.001303780964797914,\n",
              " 'meals': 0.001303780964797914,\n",
              " 'measure': 0.002607561929595828,\n",
              " 'meat': 0.001303780964797914,\n",
              " 'mechanic': 0.001303780964797914,\n",
              " 'memory': 0.001303780964797914,\n",
              " 'men': 0.002607561929595828,\n",
              " 'miles': 0.001303780964797914,\n",
              " 'minor': 0.001303780964797914,\n",
              " 'minute': 0.001303780964797914,\n",
              " 'modern': 0.001303780964797914,\n",
              " 'money': 0.002607561929595828,\n",
              " 'morning': 0.001303780964797914,\n",
              " 'morrow': 0.001303780964797914,\n",
              " 'music': 0.001303780964797914,\n",
              " 'musical': 0.002607561929595828,\n",
              " 'mysticisms': 0.001303780964797914,\n",
              " 'name': 0.001303780964797914,\n",
              " 'nature': 0.002607561929595828,\n",
              " 'navigator': 0.001303780964797914,\n",
              " 'negociant': 0.001303780964797914,\n",
              " 'new': 0.001303780964797914,\n",
              " 'news': 0.005215123859191656,\n",
              " 'night': 0.002607561929595828,\n",
              " 'not': 0.001303780964797914,\n",
              " 'notices': 0.001303780964797914,\n",
              " 'novel': 0.001303780964797914,\n",
              " 'number': 0.001303780964797914,\n",
              " 'nurse': 0.001303780964797914,\n",
              " 'nutrition': 0.002607561929595828,\n",
              " 'of': 0.007822685788787484,\n",
              " 'offices': 0.001303780964797914,\n",
              " 'old': 0.005215123859191656,\n",
              " 'on': 0.001303780964797914,\n",
              " 'one': 0.01564537157757497,\n",
              " 'ones': 0.005215123859191656,\n",
              " 'only': 0.002607561929595828,\n",
              " 'optical': 0.001303780964797914,\n",
              " 'or': 0.011734028683181226,\n",
              " 'orchestra': 0.001303780964797914,\n",
              " 'order': 0.002607561929595828,\n",
              " 'outfit': 0.001303780964797914,\n",
              " 'palatability': 0.001303780964797914,\n",
              " 'part': 0.002607561929595828,\n",
              " 'parts': 0.001303780964797914,\n",
              " 'penman': 0.001303780964797914,\n",
              " 'percentage': 0.001303780964797914,\n",
              " 'performance': 0.001303780964797914,\n",
              " 'person': 0.001303780964797914,\n",
              " 'physically': 0.001303780964797914,\n",
              " 'place': 0.001303780964797914,\n",
              " 'points': 0.001303780964797914,\n",
              " 'policeman': 0.001303780964797914,\n",
              " 'politics': 0.001303780964797914,\n",
              " 'portion': 0.001303780964797914,\n",
              " 'practice': 0.002607561929595828,\n",
              " 'prep': 0.001303780964797914,\n",
              " 'president': 0.001303780964797914,\n",
              " 'private': 0.001303780964797914,\n",
              " 'professor': 0.001303780964797914,\n",
              " 'prospects': 0.001303780964797914,\n",
              " 'purpose': 0.001303780964797914,\n",
              " 'radio': 0.001303780964797914,\n",
              " 'rather': 0.001303780964797914,\n",
              " 'reason': 0.011734028683181226,\n",
              " 'reasons': 0.002607561929595828,\n",
              " 'recommending': 0.001303780964797914,\n",
              " 'report': 0.002607561929595828,\n",
              " 'representations': 0.001303780964797914,\n",
              " 'repute': 0.001303780964797914,\n",
              " 'restaurant': 0.001303780964797914,\n",
              " 'results': 0.003911342894393742,\n",
              " 'role': 0.001303780964797914,\n",
              " 'running': 0.001303780964797914,\n",
              " 'salesman': 0.002607561929595828,\n",
              " 'sample': 0.001303780964797914,\n",
              " 'scrimmage': 0.001303780964797914,\n",
              " 'seat': 0.002607561929595828,\n",
              " 'second': 0.001303780964797914,\n",
              " 'secondhand': 0.001303780964797914,\n",
              " 'sense': 0.002607561929595828,\n",
              " 'service': 0.001303780964797914,\n",
              " 'set': 0.001303780964797914,\n",
              " 'several': 0.001303780964797914,\n",
              " 'shape': 0.001303780964797914,\n",
              " 'sharecrop': 0.001303780964797914,\n",
              " 'shipper': 0.001303780964797914,\n",
              " 'signal-to-noise': 0.001303780964797914,\n",
              " 'site': 0.001303780964797914,\n",
              " 'slice': 0.001303780964797914,\n",
              " 'sloe': 0.001303780964797914,\n",
              " 'smell': 0.001303780964797914,\n",
              " 'so': 0.001303780964797914,\n",
              " 'society': 0.002607561929595828,\n",
              " 'soil': 0.001303780964797914,\n",
              " 'song': 0.001303780964797914,\n",
              " 'songs': 0.001303780964797914,\n",
              " 'specimen': 0.001303780964797914,\n",
              " 'sportsmen': 0.001303780964797914,\n",
              " 'springs': 0.001303780964797914,\n",
              " 'standing': 0.001303780964797914,\n",
              " 'start': 0.003911342894393742,\n",
              " 'stead': 0.002607561929595828,\n",
              " 'steady': 0.001303780964797914,\n",
              " 'stereo': 0.001303780964797914,\n",
              " 'stops': 0.001303780964797914,\n",
              " 'straight': 0.001303780964797914,\n",
              " 'strong': 0.001303780964797914,\n",
              " 'sufficiently': 0.001303780964797914,\n",
              " 'taste': 0.001303780964797914,\n",
              " 'teachers': 0.003911342894393742,\n",
              " 'team': 0.001303780964797914,\n",
              " 'ten': 0.001303780964797914,\n",
              " 'than': 0.002607561929595828,\n",
              " 'that': 0.001303780964797914,\n",
              " 'thing': 0.011734028683181226,\n",
              " 'things': 0.001303780964797914,\n",
              " 'this': 0.002607561929595828,\n",
              " 'throw': 0.001303780964797914,\n",
              " 'time': 0.011734028683181226,\n",
              " 'times': 0.002607561929595828,\n",
              " 'to': 0.020860495436766623,\n",
              " 'today': 0.001303780964797914,\n",
              " 'tonight': 0.001303780964797914,\n",
              " 'tree': 0.001303780964797914,\n",
              " 'trunk': 0.001303780964797914,\n",
              " 'try': 0.001303780964797914,\n",
              " 'tumbler': 0.001303780964797914,\n",
              " 'turtle': 0.001303780964797914,\n",
              " 'two': 0.001303780964797914,\n",
              " 'use': 0.001303780964797914,\n",
              " 'verse': 0.001303780964797914,\n",
              " 'view': 0.001303780964797914,\n",
              " 'voice': 0.001303780964797914,\n",
              " 'water': 0.001303780964797914,\n",
              " 'way': 0.005215123859191656,\n",
              " 'we': 0.001303780964797914,\n",
              " 'weather': 0.002607561929595828,\n",
              " 'well': 0.001303780964797914,\n",
              " 'whatever': 0.001303780964797914,\n",
              " 'while': 0.001303780964797914,\n",
              " 'wife': 0.001303780964797914,\n",
              " 'will': 0.01694915254237288,\n",
              " 'wine': 0.001303780964797914,\n",
              " 'wishes': 0.001303780964797914,\n",
              " 'with': 0.001303780964797914,\n",
              " 'word': 0.001303780964797914,\n",
              " 'work': 0.003911342894393742,\n",
              " 'worker': 0.001303780964797914,\n",
              " 'working': 0.001303780964797914,\n",
              " 'works': 0.005215123859191656,\n",
              " 'writers': 0.001303780964797914,\n",
              " 'year': 0.00651890482398957,\n",
              " 'years': 0.002607561929595828,\n",
              " 'yff': 0.001303780964797914}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCMwdSCPluOW"
      },
      "source": [
        "# manually assign a bigram probability for P(you|Congratulations)\n",
        "bigram_model['Congratulations']['you'] = 0.05678"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF4q39dSWTmU",
        "outputId": "3cce933e-3d06-4d7e-cac1-25ea8a8b59c5"
      },
      "source": [
        "# calculate the sentence probability using the bigram model\n",
        "# P('Congratulations you have made it') = P('Congratulations')*P(you|Congratulations)*P(have|you)*P(made|have)*P(it|made)\n",
        "\n",
        "P_sent = 1\n",
        "wd_list = test_sent.split()\n",
        "for wi,wd in enumerate(wd_list):\n",
        "    if(wi == 0):\n",
        "        P_sent = P_sent*(unigram_model[wd]) # your code here\n",
        "        print(wd, float(\"%.5f\" % unigram_model[wd]))\n",
        "    else:\n",
        "        P_sent =  P_sent*(bigram_model[wd_list[wi-1]][wd_list[wi]]) # your code here\n",
        "        print(\"P(%s|%s): %.5f\" % (wd_list[wi], wd_list[wi-1], bigram_model[wd_list[wi-1]][wd_list[wi]]))  \n",
        "    \n",
        "print(\"P(%s) based on bigram model is:\" % (test_sent),P_sent)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Congratulations 2e-05\n",
            "P(you|Congratulations): 0.05678\n",
            "P(have|you): 0.03868\n",
            "P(made|have): 0.00797\n",
            "P(it|made): 0.04100\n",
            "P(Congratulations you have made it) based on bigram model is: 1.407282960001504e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHp1qVloDqC"
      },
      "source": [
        "- Build the trigram model: P(w1,w2,w3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ssxcxEWTmV"
      },
      "source": [
        "# Create a dict of dict to store trigram frequency: dict[key] = {key_1:value_1; key_2:value_2;...}\n",
        "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "\n",
        "# Count frequency of trigrams\n",
        "for sentence in brown.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        trigram_model[w1,w2][w3] += 1\n",
        "\n",
        "# Transform the counts to probabilities: count(w1_w2_w3)/total counts of all trigrams that start with w1_w2: (w1, w2, wi)\n",
        "for w1,w2 in trigram_model:\n",
        "    total_count = sum(trigram_model[w1,w2][w3] for w3 in trigram_model[w1,w2])# your code here\n",
        "    for w3 in trigram_model[w1,w2]:\n",
        "        trigram_model[w1,w2][w3] /= total_count"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTYX1-Z2WTmV",
        "outputId": "f68c3e98-2a51-4641-cf89-55ced7079782"
      },
      "source": [
        "print(trigram_model['an','investigation']['of']) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5714285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmqOggC_luUk",
        "outputId": "c13b1d22-4686-40dd-f8d4-2bf1b2250418"
      },
      "source": [
        "# check all the possible w3 in the trigram ('an', 'investigation', w3)\n",
        "dict(trigram_model['an','investigation'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 0.14285714285714285,\n",
              " 'of': 0.5714285714285714,\n",
              " 'which': 0.14285714285714285,\n",
              " 'with': 0.14285714285714285}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggh4H0UAl5Uc"
      },
      "source": [
        "# manually assign a bigram probability for P(you,Congratulations)\n",
        "trigram_model['Congratulations','you']['have'] = 0.08765"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj5MWxJnWTmW",
        "outputId": "e7bea8a7-b42d-4e0d-a204-e6371a6314f3"
      },
      "source": [
        "# calculate the sentence probability using the trigram model\n",
        "# P('Congratulations you have made it') = P('Congratulations')*P(you|Congratulations)*P(have|Congratulations,you)*P(made|you,have)*P(it|have,made)\n",
        "\n",
        "P_sent = 1\n",
        "wd_list = test_sent.split()\n",
        "for wi,wd in enumerate(wd_list):\n",
        "    if(wi == 0):\n",
        "        P_sent = P_sent*(unigram_model[wd]) # your code here\n",
        "        print(\"P(%s): %.5f\" % (wd, unigram_model[wd]))\n",
        "    elif(wi == 1):\n",
        "        P_sent =  P_sent*(bigram_model[wd_list[wi-1]][wd_list[wi]]) # your code here\n",
        "        print(\"P(%s|%s): %.5f\" % (wd_list[wi], wd_list[wi-1], bigram_model[wd_list[wi-1]][wd_list[wi]]))  \n",
        "    else:\n",
        "        P_sent = P_sent*(trigram_model[wd_list[wi-2], wd_list[wi-1]][wd_list[wi]]) # your code here\n",
        "        print(\"P(%s|%s,%s): %.5f\" % (wd_list[wi], wd_list[wi-2], wd_list[wi-1], trigram_model[wd_list[wi-2],wd_list[wi-1]][wd_list[wi]]))  \n",
        "    \n",
        "print(\"P(%s) based on trigram model is:\" % (test_sent),P_sent)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P(Congratulations): 0.00002\n",
            "P(you|Congratulations): 0.05678\n",
            "P(have|Congratulations,you): 0.08765\n",
            "P(made|you,have): 0.00935\n",
            "P(it|have,made): 0.06452\n",
            "P(Congratulations you have made it) based on trigram model is: 5.887520532622753e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5BsccZjoYSw"
      },
      "source": [
        "# Compare the performance of Logistic Regression classifier and Naive Bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bNVGYtDxnJdl",
        "outputId": "a0a1ffe2-fe50-496c-9599-b2d50306124a"
      },
      "source": [
        "# import google.colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7a6d97a-c047-4dd0-8cc7-8af902d21466\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7a6d97a-c047-4dd0-8cc7-8af902d21466\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_data.csv to df_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBZiKChrl8sC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "MMwsRSWCl8vx",
        "outputId": "ee7901f5-147d-4c29-d08a-0a17748e9fe6"
      },
      "source": [
        "df_data = pd.read_csv('df_data.csv')\n",
        "df_data.shape, display(df_data.head(2))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  One of the other reviewers has mentioned that ...      1\n",
              "1  A wonderful little production. <br /><br />The...      1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49582, 2), None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hn_fcgealjS",
        "outputId": "898c0523-cee9-48fb-c402-2cae63030131"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(lowercase=True, stop_words='english', max_df=0.8, min_df=5, \n",
        "                             ngram_range=(1,1), binary=True)\n",
        "\n",
        "X = vectorizer.fit_transform(df_data.review)\n",
        "y = df_data.label.values\n",
        "\n",
        "print(\"X.shape : \",X.shape)\n",
        "print(\"y.shape : \",y.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape :  (49582, 36669)\n",
            "y.shape :  (49582,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rfG1hW-mBy_"
      },
      "source": [
        "# train test split\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "random.seed(42)\n",
        "\n",
        "def split_train_test(train_fraction, test_fraction):\n",
        "    df_data_reidx = df_data.reset_index(drop=True) # reset index in case there are gaps\n",
        "    train_idx, test_idx = train_test_split(np.arange(df_data_reidx.shape[0]), \n",
        "                                           train_size=train_fraction, test_size=test_fraction, \n",
        "                                           shuffle=True, random_state=42)\n",
        "\n",
        "    # len(train_idx), len(test_idx)\n",
        "    # print(\"Number of training examples:{}\".format(len(train_idx)))\n",
        "    # print(\"Number of testing examples:{}\".format(len(test_idx)))\n",
        "\n",
        "    X_train = X[train_idx]\n",
        "    y_train = y[train_idx]\n",
        "\n",
        "    X_test = X[test_idx]\n",
        "    y_test = y[test_idx]\n",
        "\n",
        "    print(\"Training data: X_train : {}, y_train : {}\".format(X_train.shape, y_train.shape))\n",
        "    print(\"Testing data: X_test : {}, y_test : {}\".format(X_test.shape, y_test.shape))\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwp3cpVbawOR",
        "outputId": "b5e7391b-2715-4439-eaa3-ea8521402867"
      },
      "source": [
        "X_train, y_train, X_test, y_test = split_train_test(train_fraction=0.8, test_fraction=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: X_train : (39665, 36669), y_train : (39665,)\n",
            "Testing data: X_test : (9917, 36669), y_test : (9917,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zwn1vhjw7X2"
      },
      "source": [
        "- Fit a Logistic Regression classifier and check its performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNkf_TqVazfW",
        "outputId": "7c136d85-51cc-42a4-eb50-c3696704c508"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def evaluate_LR():\n",
        "    LR_clf = LogisticRegression(solver='liblinear')\n",
        "    LR_clf.fit(X_train, y_train)\n",
        "    y_LRpred_test = LR_clf.predict(X_test)\n",
        "    print(classification_report(y_test, y_LRpred_test)) # write your code inside the function\n",
        "\n",
        "evaluate_LR()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      4939\n",
            "           1       0.87      0.89      0.88      4978\n",
            "\n",
            "    accuracy                           0.88      9917\n",
            "   macro avg       0.88      0.88      0.88      9917\n",
            "weighted avg       0.88      0.88      0.88      9917\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIxWDDblw-v6"
      },
      "source": [
        "- Fit a Naive Bayes classifier and check its performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7nW7saof55M",
        "outputId": "052ff6ed-6200-4fb2-a3e0-0d66b564188c"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "def evaluate_NB():\n",
        "    NB_clf = BernoulliNB()\n",
        "    NB_clf.fit(X_train, y_train)\n",
        "    y_NBpred_test = NB_clf.predict(X_test)# your code here: apply the classifier to make prediction on test set\n",
        "    print(classification_report(y_test, y_NBpred_test))\n",
        "\n",
        "evaluate_NB()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      4939\n",
            "           1       0.87      0.83      0.85      4978\n",
            "\n",
            "    accuracy                           0.85      9917\n",
            "   macro avg       0.85      0.85      0.85      9917\n",
            "weighted avg       0.85      0.85      0.85      9917\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQg2bMfxxSBw"
      },
      "source": [
        "- Select a small number of training data, re-fit the two classifiers and compare their performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reH2DSYRmM6u",
        "outputId": "944b16a5-8db6-4207-fd71-b0139036650e"
      },
      "source": [
        "X_train, y_train, X_test, y_test = split_train_test(train_fraction=0.3, test_fraction=0.2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: X_train : (14874, 36669), y_train : (14874,)\n",
            "Testing data: X_test : (9917, 36669), y_test : (9917,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCZqFKU3l5ad",
        "outputId": "e655c4fa-e508-4afa-e644-e4db0c564373"
      },
      "source": [
        "# evaluate the LR classifier performance on new training and testing data\n",
        "evaluate_LR() # your code here (one line)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86      4939\n",
            "           1       0.85      0.87      0.86      4978\n",
            "\n",
            "    accuracy                           0.86      9917\n",
            "   macro avg       0.86      0.86      0.86      9917\n",
            "weighted avg       0.86      0.86      0.86      9917\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TozqORBomTsd",
        "outputId": "953ed454-24e2-4ba2-d4f2-4810de8bba44"
      },
      "source": [
        "# evaluate the NB classifier performance on new training and testing data\n",
        "evaluate_NB() # your code here (one line)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      4939\n",
            "           1       0.86      0.82      0.84      4978\n",
            "\n",
            "    accuracy                           0.85      9917\n",
            "   macro avg       0.85      0.85      0.85      9917\n",
            "weighted avg       0.85      0.85      0.85      9917\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}